{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('src')\n",
    "\n",
    "import config\n",
    "from models import get_model\n",
    "from datasets.brain_tumor_dataset import get_dataloaders\n",
    "from losses.combined_loss import MultiTaskLoss\n",
    "from utils.metrics import calculate_classification_metrics, calculate_iou, count_parameters\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Model: {config.MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration (Edit Here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration (Modify as needed)\n",
    "MODEL_NAME = 'lightweight_transformer'  # Options: 'unet', 'resnet_unet', 'vit', 'swin', 'lightweight_transformer'\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "SAVE_EVERY = 5  # Save checkpoint every N epochs\n",
    "\n",
    "# Update config\n",
    "config.MODEL_NAME = MODEL_NAME\n",
    "config.BATCH_SIZE = BATCH_SIZE\n",
    "config.NUM_EPOCHS = NUM_EPOCHS\n",
    "config.LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Device: {config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading datasets...\")\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    train_dir=config.TRAIN_DIR,\n",
    "    val_dir=config.VAL_DIR,\n",
    "    test_dir=config.TEST_DIR,\n",
    "    train_ann=config.TRAIN_ANNOTATIONS,\n",
    "    val_ann=config.VAL_ANNOTATIONS,\n",
    "    test_ann=config.TEST_ANNOTATIONS,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    image_size=config.IMAGE_SIZE\n",
    ")\n",
    "\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initializing {MODEL_NAME} model...\")\n",
    "model = get_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    n_classes_seg=config.SEGMENTATION_CLASSES,\n",
    "    n_classes_cls=config.NUM_CLASSES - 1,\n",
    "    img_size=config.IMAGE_SIZE\n",
    ").to(config.DEVICE)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f\"✓ Model initialized\")\n",
    "print(f\"  Parameters: {num_params:,} ({num_params/1e6:.2f}M)\")\n",
    "\n",
    "# Initialize loss, optimizer, scheduler\n",
    "criterion = MultiTaskLoss(\n",
    "    classification_weight=config.CLASSIFICATION_WEIGHT,\n",
    "    segmentation_weight=config.SEGMENTATION_WEIGHT\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "print(\"✓ Optimizer and scheduler ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop with Live Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_cls_acc': [], 'val_cls_acc': [],\n",
    "    'train_seg_iou': [], 'val_seg_iou': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Starting training for {NUM_EPOCHS} epochs...\\n\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    # ============= TRAINING =============\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_cls_preds, all_cls_targets = [], []\n",
    "    all_seg_preds, all_seg_targets = [], []\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(config.DEVICE)\n",
    "        seg_masks = batch['segmentation_mask'].to(config.DEVICE)\n",
    "        cls_labels = batch['classification_label'].to(config.DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cls_output, seg_output = model(images)\n",
    "        \n",
    "        loss_dict = criterion(cls_output, seg_output, cls_labels, seg_masks)\n",
    "        loss = loss_dict['total_loss']\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        all_cls_preds.append(torch.argmax(cls_output, dim=1).cpu())\n",
    "        all_cls_targets.append(cls_labels.cpu())\n",
    "        all_seg_preds.append(torch.argmax(seg_output, dim=1).cpu())\n",
    "        all_seg_targets.append(seg_masks.cpu())\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_cls_acc = calculate_classification_metrics(\n",
    "        torch.cat(all_cls_preds), torch.cat(all_cls_targets)\n",
    "    )['accuracy']\n",
    "    train_seg_iou = calculate_iou(\n",
    "        torch.cat(all_seg_preds), torch.cat(all_seg_targets), num_classes=2\n",
    "    )\n",
    "    \n",
    "    # ============= VALIDATION =============\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_cls_preds, all_cls_targets = [], []\n",
    "    all_seg_preds, all_seg_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(config.DEVICE)\n",
    "            seg_masks = batch['segmentation_mask'].to(config.DEVICE)\n",
    "            cls_labels = batch['classification_label'].to(config.DEVICE)\n",
    "            \n",
    "            cls_output, seg_output = model(images)\n",
    "            loss_dict = criterion(cls_output, seg_output, cls_labels, seg_masks)\n",
    "            val_loss += loss_dict['total_loss'].item()\n",
    "            \n",
    "            all_cls_preds.append(torch.argmax(cls_output, dim=1).cpu())\n",
    "            all_cls_targets.append(cls_labels.cpu())\n",
    "            all_seg_preds.append(torch.argmax(seg_output, dim=1).cpu())\n",
    "            all_seg_targets.append(seg_masks.cpu())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_cls_acc = calculate_classification_metrics(\n",
    "        torch.cat(all_cls_preds), torch.cat(all_cls_targets)\n",
    "    )['accuracy']\n",
    "    val_seg_iou = calculate_iou(\n",
    "        torch.cat(all_seg_preds), torch.cat(all_seg_targets), num_classes=2\n",
    "    )\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_cls_acc'].append(train_cls_acc)\n",
    "    history['val_cls_acc'].append(val_cls_acc)\n",
    "    history['train_seg_iou'].append(train_seg_iou)\n",
    "    history['val_seg_iou'].append(val_seg_iou)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # ============= LIVE PLOTTING =============\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Classification Accuracy\n",
    "    axes[1].plot(history['train_cls_acc'], label='Train Acc', marker='o')\n",
    "    axes[1].plot(history['val_cls_acc'], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Classification Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Segmentation IoU\n",
    "    axes[2].plot(history['train_seg_iou'], label='Train IoU', marker='o')\n",
    "    axes[2].plot(history['val_seg_iou'], label='Val IoU', marker='s')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Mean IoU')\n",
    "    axes[2].set_title('Segmentation IoU')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Train Cls Acc: {train_cls_acc:.4f} | Val Cls Acc: {val_cls_acc:.4f}\")\n",
    "    print(f\"  Train Seg IoU: {train_seg_iou:.4f} | Val Seg IoU: {val_seg_iou:.4f}\")\n",
    "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{config.CHECKPOINT_DIR}/{MODEL_NAME}_best.pth')\n",
    "        print(f\"  ✓ Best model saved (val_loss: {val_loss:.4f})\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Save periodic checkpoint\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, f'{config.CHECKPOINT_DIR}/{MODEL_NAME}_epoch_{epoch}.pth')\n",
    "        print(f\"  ✓ Checkpoint saved\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"\\n⚠ Early stopping triggered after {epoch} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n✓ Training completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
    "with open(f'{config.RESULTS_DIR}/{MODEL_NAME}_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "print(f\"✓ Training history saved to {config.RESULTS_DIR}/{MODEL_NAME}_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Test on Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and test on one sample\n",
    "checkpoint = torch.load(f'{config.CHECKPOINT_DIR}/{MODEL_NAME}_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Get one test sample\n",
    "test_batch = next(iter(test_loader))\n",
    "image = test_batch['image'][:1].to(config.DEVICE)\n",
    "seg_mask_gt = test_batch['segmentation_mask'][:1].cpu().numpy()[0]\n",
    "cls_label_gt = test_batch['classification_label'][:1].cpu().numpy()[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    cls_output, seg_output = model(image)\n",
    "    cls_pred = torch.argmax(cls_output, dim=1).cpu().numpy()[0]\n",
    "    seg_pred = torch.argmax(seg_output, dim=1).cpu().numpy()[0]\n",
    "\n",
    "# Denormalize image\n",
    "img = image[0].cpu().numpy().transpose(1, 2, 0)\n",
    "img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "img = np.clip(img, 0, 1)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img)\n",
    "axes[1].imshow(seg_mask_gt, alpha=0.5, cmap='Reds')\n",
    "axes[1].set_title(f'Ground Truth\\nClass: {cls_label_gt}')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(img)\n",
    "axes[2].imshow(seg_pred, alpha=0.5, cmap='Reds')\n",
    "axes[2].set_title(f'Prediction\\nClass: {cls_pred}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Classification: GT={cls_label_gt}, Pred={cls_pred}, {'✓ Correct' if cls_pred == cls_label_gt else '✗ Wrong'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_tumor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
