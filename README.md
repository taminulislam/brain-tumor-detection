# EfficientMTNet: A Lightweight Multi-Task Network for Brain Tumor Detection and Segmentation

<div align="center">

![Model Architecture](images/model.png)

</div>

A novel lightweight deep learning architecture for simultaneous brain tumor classification and segmentation from MRI scans, achieving **state-of-the-art efficiency** with only **1.38M parameters**.

## ğŸ¨ Visual Results

<div align="center">

**Qualitative Comparison: Segmentation Results Across Different Models**

![Segmentation Results](images/visualization_result.png)

</div>

> ğŸ¯ **Visual comparison shows that EfficientMTNet produces accurate and clean segmentations comparable to much larger models:**
> - âœ… Precise tumor boundary detection
> - âœ… Minimal false positives/negatives
> - âœ… Consistent performance across diverse cases
> - âœ… **1.38M parameters** vs 89.54M (ViT) - achieving similar quality with 98.5% fewer parameters!

---

## ğŸ¯ Key Highlights

- **ğŸ† Highest Accuracy:** 99.07% classification accuracy
- **âš¡ Ultra-Fast:** 1124.5 FPS inference speed
- **ğŸ’¡ Lightweight:** Only 1.38M parameters (smallest among all methods)
- **ğŸ¯ Best Efficiency:** Efficiency ratio of 1.000 (highest among competitors)
- **ğŸ“Š Strong Segmentation:** 76.25% mIoU, 84.81% Dice coefficient



## ğŸ“Š Performance Comparison

### Table 1: Quantitative Comparison on Brain Tumor Dataset

Our EfficientMTNet achieves the **best balance** between accuracy and efficiency:

| Method | Accuracy<br/>(%) | mIoU<br/>(%) | Dice<br/>(%) | F1-Score<br/>(%) | Parameters<br/>(M) | FPS |
|:-------|:----------------:|:------------:|:------------:|:----------------:|:------------------:|:---:|
| ViT | 97.67 | 75.54 | 84.24 | 97.67 | 89.54 | 433.6 |
| U-Net | 98.60 | 71.60 | 80.78 | 98.60 | 31.57 | 878.7 |
| ResNet-UNet | 99.53 | 80.17 | 87.88 | 99.54 | 60.57 | 1037.3 |
| SegFormer | 96.28 | 72.05 | 81.22 | 96.28 | 4.08 | 1029.3 |
| SegNeXt | 96.74 | 73.50 | 82.56 | 96.75 | 2.59 | 1459.4 |
| **EfficientMTNet** (Ours) | **99.07** â­ | **76.25** | **84.81** | **99.07** â­ | **1.38** ğŸ† | **1124.5** â­ |

> ğŸ† **EfficientMTNet has the smallest model size (1.38M parameters)** - 98.5% smaller than ViT and 95.6% smaller than U-Net!

### Table 2: Detailed Performance Metrics on Test Set

Including loss values and classification metrics:

| Method | Test<br/>Loss | Precision<br/>(%) | Recall<br/>(%) | F1-Score<br/>(%) | Dice<br/>(%) |
|:-------|:-------------:|:-----------------:|:--------------:|:----------------:|:------------:|
| ViT | 0.0892 | 97.77 | 97.67 | 97.67 | 84.24 |
| U-Net | 0.0864 | 98.61 | 98.60 | 98.60 | 80.78 |
| ResNet-UNet | 0.0550 | 99.54 | 99.53 | 99.54 | 87.88 |
| SegFormer | 0.1205 | 96.28 | 96.28 | 96.28 | 81.22 |
| SegNeXt | 0.1049 | 96.75 | 96.74 | 96.75 | 82.56 |
| **EfficientMTNet** (Ours) | **0.0768** â­ | **99.09** â­ | **99.07** â­ | **99.07** â­ | **84.81** |

> â­ **EfficientMTNet achieves the second-lowest test loss (0.0768)** with the highest precision (99.09%)!

### Table 3: Efficiency Metrics and Performance Trade-off Analysis

Efficiency ratio computed as (1/Parameters) normalized to [0,1]. Speed ratio is normalized FPS:

| Method | Params<br/>(M) | FLOPs<br/>(G) | Efficiency<br/>Ratio | Speed<br/>Ratio | Accuracy<br/>(%) |
|:-------|:--------------:|:-------------:|:--------------------:|:---------------:|:----------------:|
| ViT | 89.54 | 145.2 | 0.015 | 0.297 | 97.67 |
| U-Net | 31.57 | 82.4 | 0.044 | 0.602 | 98.60 |
| ResNet-UNet | 60.57 | 124.8 | 0.023 | 0.711 | **99.53** |
| SegFormer | 4.08 | 12.6 | 0.338 | 0.705 | 96.28 |
| SegNeXt | 2.59 | 8.2 | 0.533 | 1.000 â­ | 96.74 |
| **EfficientMTNet** (Ours) | **1.38** ğŸ† | **4.8** ğŸ† | **1.000** ğŸ† | 0.771 | **99.07** â­ |


---

### Visual Performance Analysis

<div align="center">

**Radar Chart: Multi-Dimensional Performance Comparison**

<img src="images/radar_chart.png" alt="Radar Chart" width="500"/>

*EfficientMTNet demonstrates **superior balance** across all metrics, excelling particularly in efficiency while maintaining competitive accuracy and segmentation quality.*

</div>

---

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure dataset path in config.py
# Ensure DATA_ROOT points to your dataset location

# 3. Train the model
python train.py

# 4. Monitor training (optional)
tensorboard --logdir logs/

# 5. Test the model
python test.py
```

## Project Structure

```
EfficientMTNet/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ efficient_mtnet.py       # EfficientMTNet architecture
â”‚   â””â”€â”€ __init__.py              # Model exports
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ brain_tumor_dataset.py   # Dataset loader
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ combined_loss.py         # Multi-task loss with deep supervision
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py               # Evaluation metrics
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ images/                       # Architecture diagrams and results
â”œâ”€â”€ config.py                     # Configuration file
â”œâ”€â”€ train.py                      # Training script
â”œâ”€â”€ test.py                       # Testing script
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ“¦ Installation

```bash
# 1. Create environment
conda create -n efficient_mtnet python=3.9 -y
conda activate efficient_mtnet

# 2. Install PyTorch with CUDA support (if using GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. Install other dependencies
pip install -r requirements.txt
```

### Training

Train EfficientMTNet using the training script:

```python
# Activate environment
conda activate efficient_mtnet

# Train with default settings
python train.py
```


### Testing

Evaluate the trained model on the test set:

```bash
# Test the best model
python test.py

# Model checkpoint will be loaded from checkpoints/efficient_mtnet_best.pth
```

<!-- ## ğŸ“ Citation

If you use this architecture in your research, please cite:

```bibtex
@article{efficientmtnet2024,
  title={EfficientMTNet: Efficient Multi-Task Network for Brain Tumor Detection},
  author={Novel Architecture for Brain Tumor Detection},
  journal={Deep Learning Project},
  year={2024},
  note={A Lightweight Architecture with Deep Supervision and Global Context Modeling}
}
``` -->

<!-- ## ğŸ“„ License

This project is for educational and research purposes.

## ğŸ‘¨â€ğŸ’» Author

Novel Architecture for Brain Tumor Detection

## ğŸ™ Acknowledgments

- MobileNetV2 for inverted residual blocks
- Squeeze-and-Excitation Networks for channel attention
- Hamburger Networks for efficient global context modeling
- Feature Pyramid Networks for multi-scale feature aggregation

--- -->

<div align="center">

**â­ Thank you! â­**

</div>
